# experiment
data_root: ../data/training_data/
training_name: swint
trainer: BatCLSTrainer

# training
n_epochs: 20
batch_size: 8
learning_rate: 1e-4
optimizer: Adam
base_lr: 0.001
max_lr: 0.01
step_size_up: 3
scheduler_mode: triangular
weight_decay: 0.0003
use_amp: True

# loss
loss: FocalLoss
class_weights: True

# architecture
model_name: swin_base_patch4_window12_384
pretrained: True
num_classes: 96

# checkpoint
checkpoint_metric: acc
checkpoint_metric_goal: maximize

# dataset
input_size: [384, 384]
seed: 42
train_size: 0.7
val_size: 0.15
mean: None #[0.485, 0.456, 0.406]
std: None #[0.229, 0.224, 0.225]

# augmentations
rotation_degrees: 15
sharpness_factor: 2
brightness: 0.2
contrast: 0.2
saturation: 0.2
hue: 0.1